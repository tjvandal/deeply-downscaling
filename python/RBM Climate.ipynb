{
 "metadata": {
  "name": "",
  "signature": "sha256:393d1c61fe701ea38007a7ef13a7ff8268f7d58a430d381d6c88082c063aeba3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "from netCDF4 import Dataset, num2date\n",
      "import numpy\n",
      "from matplotlib import pyplot\n",
      "#%matplotlib inline\n",
      "import datetime\n",
      "\n",
      "sys.path.append(os.path.join(os.path.expanduser(\"~\"), \"repos/deep-learning/lib\"))\n",
      "from dbn import DeepBeliefNet\n",
      "from rbm import RBM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = os.path.join(os.path.expanduser(\"~\"), \"Dropbox/research/elastic-net-downscaling/data/\")\n",
      "ncep_ncar = os.path.join(data_dir, \"ncep_ncar\")\n",
      "observed_file = os.path.join(data_dir, \"obs_prcp.nc\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "observed_data = Dataset(observed_file)\n",
      "t = observed_data.variables['time'][:]\n",
      "t = num2date(t, \"days since 1950-01-01 00:00:00\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "variables = [\"air\"] # \"pres\", \"rhum\", \"slp\", \"pr_wtr\", \"uwnd\", \"vwnd\"]\n",
      "exten = \".mon.mean.nc\"\n",
      "data = Dataset(os.path.join(ncep_ncar, \"air\"+exten))\n",
      "t2 = data.variables[\"time\"][:]\n",
      "t2 = num2date(t2, \"hours since 1800-01-01 00:00:0.0\")\n",
      "rows = (t2 >= datetime.datetime(1950, 1, 1)) & (t2 < datetime.datetime(2000, 1, 1))\n",
      "numpy.reshape(data.variables['air'][rows], (600,  73*144)).shape  # confirm there are 600 rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(600, 10512)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_lat = 75\n",
      "min_lat = 0\n",
      "min_lon = 180\n",
      "max_lon = 315\n",
      "\n",
      "data =  Dataset(os.path.join(ncep_ncar, \"air\"+exten))\n",
      "lat_vals = data.variables[\"lat\"][:]\n",
      "lon_vals = data.variables[\"lon\"][:]\n",
      "lon_cols = (lon_vals >= min_lon) & (lon_vals <= max_lon)\n",
      "lat_cols = (lat_vals >= min_lat) & (lat_vals <= max_lat)\n",
      "nlon = sum(lon_cols)\n",
      "nlat = sum(lat_cols)\n",
      "cols = len(variables)*nlat*nlon\n",
      "gridded = numpy.empty((sum(rows), cols))\n",
      "\n",
      "for i, var in enumerate(variables):\n",
      "    data = Dataset(os.path.join(ncep_ncar, var+exten))\n",
      "    arr = numpy.reshape(data.variables[var][rows, lat_cols, lon_cols], \n",
      "                        (sum(rows), nlon*nlat))\n",
      "    \n",
      "    start = i*nlon*nlat\n",
      "    gridded[:, start:(start+nlon*nlat)] = arr\n",
      "\n",
      "observed_data.variables[\"Prcp\"][1, :, :].mask.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "26545"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape = observed_data.variables[\"Prcp\"][:].shape\n",
      "lt = 176-1\n",
      "ln = 23-1\n",
      "y = observed_data.variables[\"Prcp\"][:, lt, ln]\n",
      "normalized_gridded = (gridded - gridded[:400].mean(axis=0)) / gridded[:400].std(axis=0)\n",
      "#normalized_gridded = (normalized_gridded.T - normalized_gridded.T.mean(axis=0)) / normalized_gridded.T.std(axis=0)\n",
      "#normalized_gridded = normalized_gridded.T\n",
      "\n",
      "def expit(x, beta=1):\n",
      "    return 1 / (1 + numpy.exp(-beta * x))\n",
      "\n",
      "squashed_gridded = expit(normalized_gridded, beta=1)\n",
      "height, bins = numpy.histogram(squashed_gridded, bins=100)\n",
      "pyplot.bar(bins[:-1], height, width=1/100.)\n",
      "\n",
      "pyplot.imshow(squashed_gridded[13].reshape(nlat,nlon))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<matplotlib.image.AxesImage at 0x7f896fd9ed10>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boltzmann = RBM(plot_histograms=True)\n",
      "boltzmann.fit(squashed_gridded)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<repr(<rbm.RBM at 0x7f89b4448790>) failed: RuntimeError: maximum recursion depth exceeded while calling a Python object>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}